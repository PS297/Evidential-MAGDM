## Importing the necessary libraries
import os
import cv2
import numpy as np
from PIL import Image 
import Augmentor
from Augmentor import Pipeline
import torch
import torch.nn as nn
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from skimage import color
import matplotlib.pyplot as plt
import glob
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score, recall_score, f1_score, roc_auc_score, multilabel_confusion_matrix
from sklearn.preprocessing import label_binarize
import pandas as pd
import math
from sklearn import preprocessing
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR
from torchvision import models, transforms
from torch.utils.data import DataLoader, TensorDataset

## Loading the Augmented training dataset
######################## Generate Scale Space using Gaussian Smoothing by varying the standard deviation ################
def MultiScale(image , sigma):
    kernel_size = 3
    blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)
    return blurred_image

SIZE = 224


train_images_S1 = []
train_images_S2 = []
train_images_S3 =[]
train_labels = []

for directory_path in glob.glob("OCTDL/Augment/train/*"):
    label = directory_path.split("/")[-1]
    

    for img_path in glob.glob(os.path.join(directory_path , "*.jpg")):
         gray_img = cv2.imread(img_path , cv2.IMREAD_COLOR)
         gray_img = cv2.resize(gray_img , (SIZE , SIZE))
         img = gray_img             
         img_S1 = MultiScale(img , 1)
         img_S2 = MultiScale(img , 2)
         img_S3 = MultiScale(img , 3)
         train_images_S1.append(img_S1)
         train_images_S2.append(img_S2)
         train_images_S3.append(img_S3)
         train_labels.append(label)

    for img_path in glob.glob(os.path.join(directory_path , "*.png")):
         gray_img = cv2.imread(img_path , cv2.IMREAD_COLOR)
         gray_img = cv2.resize(gray_img , (SIZE , SIZE))
         img = gray_img                     # np.repeat(gray_img[:, :, np.newaxis], 3, axis=2)
         img_S1 = MultiScale(img , 1)
         img_S2 = MultiScale(img , 2)
         img_S3 = MultiScale(img , 3)
         train_images_S1.append(img_S1)
         train_images_S2.append(img_S2)
         train_images_S3.append(img_S3)
         train_labels.append(label)

## Loding the test dataset
test_images_S1 = []
test_images_S2 = []
test_images_S3 = []
test_labels = []

for directory_path in glob.glob("OCTDL/val/*"):
    label = directory_path.split("/")[-1]
    for img_path in glob.glob(os.path.join(directory_path , "*.jpg")):
         gray_img = cv2.imread(img_path , cv2.IMREAD_COLOR)
         gray_img = cv2.resize(gray_img , (SIZE , SIZE))
         img = gray_img                   
         img_S1 = MultiScale(img , 1)
         img_S2 = MultiScale(img , 2)
         img_S3 = MultiScale(img , 3)
         test_images_S1.append(img_S1)
         test_images_S2.append(img_S2)
         test_images_S3.append(img_S3)
         test_labels.append(label)   
for img_path in glob.glob(os.path.join(directory_path , "*.png")):
         gray_img = cv2.imread(img_path , cv2.IMREAD_COLOR)
         gray_img = cv2.resize(gray_img , (SIZE , SIZE))
         img = gray_img                    
         img_S1 = MultiScale(img , 1)
         img_S2 = MultiScale(img , 2)
         img_S3 = MultiScale(img , 3)
         test_images_S1.append(img_S1)
         test_images_S2.append(img_S2)
         test_images_S3.append(img_S3)
         test_labels.append(label)    
print(len(train_images_S1))
print(len(train_images_S2))
print(len(train_images_S3))

print(len(test_images_S1))
print(len(test_images_S2))
print(len(test_images_S3))

## Normalizing the dataset
train_images_S1 = np.array(train_images_S1) / 255.0
train_images_S2 = np.array(train_images_S2) / 255.0
train_images_S3 = np.array(train_images_S3) / 255.0
train_labels = np.array(train_labels)

test_images_S1 = np.array(test_images_S1) / 255.0
test_images_S2 = np.array(test_images_S2) / 255.0
test_images_S3 = np.array(test_images_S3) / 255.0
test_labels = np.array(test_labels)

## Label Encoder
le = preprocessing.LabelEncoder()
le.fit(test_labels)
test_labels_encoded = le.transform(test_labels)

le.fit(train_labels)
train_labels_encoded = le.transform(train_labels)

X_train_S1 , Y_train , X_test_S1 , Y_test = train_images_S1 , train_labels_encoded , test_images_S1 , test_labels_encoded
X_train_S2 , X_test_S2 = train_images_S2 , test_images_S2
X_train_S3 , X_test_S3 = train_images_S3 , test_images_S3

## Converting the dataset into tesor and loader
y_train = torch.tensor(Y_train, dtype=torch.long)
y_test = torch.tensor(Y_test, dtype=torch.long)

X_train = torch.tensor(X_train_S3, dtype=torch.float32).permute(0, 3, 1, 2)  
X_test = torch.tensor(X_test_S3, dtype=torch.float32).permute(0, 3, 1, 2)

train_dataset = TensorDataset(X_train, y_train)
test_dataset = TensorDataset(X_test, y_test)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

num_classes = len(torch.unique(y_train))
print(num_classes)

## Defining the structure of the EfficientNet-B0 model
